{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be0e8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2fc0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_00=\"/home/mustapha/Downloads/data_65.csv\"\n",
    "DF = pd.read_csv(data_00)\n",
    "df = DF.iloc[:176]\n",
    "df1 = DF.iloc[176:].reset_index(drop=True)\n",
    "\n",
    "df.info()\n",
    "# df=pd.read_csv(data_00)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace6a3f8",
   "metadata": {},
   "source": [
    "## Transforming features to Material Formula ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef18e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_to_material_formula(row):\n",
    "    # Extract the values from each column\n",
    "    a = row['Li stoichiometry']\n",
    "    b = row['La stoichiometry']\n",
    "    c = row['Zr stoichiometry']\n",
    "    x = row['Li site dopant stoichiometry']\n",
    "    y = row['La site dopant stoichiometry']\n",
    "    z = row['Zr site dopant stoichiometry']\n",
    "    M = row['li_dopant']\n",
    "    N = row['la_dopant']\n",
    "    K = row['zr_dopant']\n",
    "\n",
    "\n",
    "    formula = ''\n",
    "\n",
    "\n",
    "    if a > 0:\n",
    "        formula += f'Li{a:.1f}'\n",
    "\n",
    "    # Add M if x > 0\n",
    "    if x > 0:\n",
    "        formula += f'{M}{x:.1f}'\n",
    "\n",
    "    # Add La with its stoichiometry\n",
    "    if b > 0:\n",
    "        formula += f'La{b:.1f}'\n",
    "\n",
    "    # Add N if y > 0\n",
    "    if y > 0:\n",
    "        formula += f'{N}{y:.1f}'\n",
    "\n",
    "    # Add Zr with its stoichiometry\n",
    "    if c > 0:\n",
    "        formula += f'Zr{c:.1f}'\n",
    "\n",
    "    # Add K if z > 0\n",
    "    if z > 0:\n",
    "        formula += f'{K}{z:.1f}'\n",
    "        \n",
    "    formula += f'O12'\n",
    "   \n",
    "    return formula\n",
    "\n",
    "\n",
    "df['MaterialFormula'] = df.apply(transform_to_material_formula, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9648eff",
   "metadata": {},
   "source": [
    "## Tailored one-hot encoding strategy ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22edeb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding_li(df):\n",
    "    u_l=pd.unique(df[\"li_dopant\"]) # list containing the unique Li site dopants\n",
    "    d={}\n",
    "    for x in u_l:        \n",
    "        if isinstance(x,str): # check if the type of this object is not 'Nan'\n",
    "            d[x] = [] \n",
    "    for i in range(len(df[\"li_dopant\"])):\n",
    "        for k in d:\n",
    "            if k == df[\"li_dopant\"][i]:\n",
    "                d[k].append(df[\"Li site dopant stoichiometry\"][i])\n",
    "                #if the site of col site is doped with that element\n",
    "            else:\n",
    "                d[k].append(0)\n",
    "                # 0 if not\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec14710",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def one_hot_encoding_la(df):\n",
    "        u_l=pd.unique(df[\"la_dopant\"]) \n",
    "        d={}\n",
    "        for x in u_l:        \n",
    "            if isinstance(x,str):\n",
    "                d[x] = [] \n",
    "        for i in range(len(df[\"la_dopant\"])):\n",
    "            for k in d:\n",
    "                if k == df[\"la_dopant\"][i]:\n",
    "                    d[k].append(df[\"La site dopant stoichiometry\"][i])\n",
    "                    # 1 if the site of col site is doped with that element\n",
    "                else:\n",
    "                    d[k].append(0)\n",
    "                    # 0 if not\n",
    "        return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64445d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding_zr(df):\n",
    "    u_l=pd.unique(df[\"zr_dopant\"])\n",
    "    d={}\n",
    "    for x in u_l:        \n",
    "        if isinstance(x,str): \n",
    "            d[x] = []\n",
    "    for i in range(len(df[\"zr_dopant\"])):\n",
    "        for k in d:\n",
    "            if k == df[\"zr_dopant\"][i]:\n",
    "                d[k].append(df[\"Zr site dopant stoichiometry\"][i])\n",
    "                # 1 if the site of col site is doped with that element\n",
    "            else:\n",
    "                d[k].append(0)\n",
    "                # 0 if not\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655a264d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nouveau_dataset={}\n",
    "li_dopant=pd.DataFrame(one_hot_encoding_li(df)) # replace li_dopant  with one_hot_encoding(li_dopant)\n",
    "for key in li_dopant.columns:\n",
    "    nouveau_dataset[key]=list(li_dopant[key]) \n",
    "#     nouveau_dataset[\"li_dopant_\"+key]=list(li_dopant[key]) \n",
    "li_dopant[19:28]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c5be82",
   "metadata": {},
   "outputs": [],
   "source": [
    "la_dopant=pd.DataFrame(one_hot_encoding_la(df))\n",
    "for key in la_dopant.columns:\n",
    "    nouveau_dataset[key]=list(la_dopant[key])\n",
    "#     nouveau_dataset[\"la_dopant_\"+key]=list(la_dopant[key])\n",
    "la_dopant[19:28]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93b88d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "zr_dopant=pd.DataFrame(one_hot_encoding_zr(df))\n",
    "for key in zr_dopant.columns:\n",
    "    nouveau_dataset[key]=list(zr_dopant[key])\n",
    "#     nouveau_dataset[\"zr_dopant_\"+key]=list(zr_dopant[key])\n",
    "zr_dopant[19:28]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdeec6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# addition of a new column to define which is the doped site\n",
    "df.loc[df['Li site dopant stoichiometry'] != 0, 'li'] = 1 # 1 if the material is doped in the Li site\n",
    "df.loc[df['Li site dopant stoichiometry'] == 0, 'li'] = 0 # 0 if not\n",
    "\n",
    "df.loc[df['La site dopant stoichiometry'] != 0, 'la'] = 1 # 1 if the material is doped in the Li site\n",
    "df.loc[df['La site dopant stoichiometry'] == 0, 'la'] = 0 # 0 if not\n",
    "\n",
    "df.loc[df['Zr site dopant stoichiometry'] != 0, 'zr'] = 1 # 1 if the material is doped in the Li site\n",
    "df.loc[df['Zr site dopant stoichiometry'] == 0, 'zr'] = 0 # 0 if not\n",
    "\n",
    "df.head(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e26757",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataset=pd.DataFrame(nouveau_dataset) # New dataset \n",
    "# new_dataset[19:28]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e4cd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of df:\", df.shape)\n",
    "print(\"Shape of nouveau_dataset:\", new_dataset.shape)\n",
    "    \n",
    "# adding dopant elements to construct  DataFrame X    \n",
    "X= pd.concat([df, new_dataset], axis=1)\n",
    "\n",
    "# X.info()\n",
    "print(\"Shape of df:\", X.shape)\n",
    "\n",
    "# Y.shape\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d49421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Droping columns to perform feature combinations on 'df'\n",
    "\n",
    "X = X.drop(['Ionic conductivity'],axis=1)\n",
    "X = X.drop(['Publication year','Quality of ionic conductivity','Doping strategy'], axis=1)\n",
    "# X = X.drop(['T of the conductivity C'], axis=1)\n",
    "X = X.drop(['MaterialFormula','source'],axis=1)\n",
    "X = X.drop(['li','la','zr'], axis=1)\n",
    "X = X.drop(['Li site dopant ionic radius','La site dopant ionic radius','Zr site dopant ionic radius'], axis=1)\n",
    "# X = X.drop(['Li stoichiometry','La stoichiometry', 'Zr stoichiometry'], axis=1)\n",
    "X = X.drop(['Li site dopant stoichiometry','La site dopant stoichiometry','Zr site dopant stoichiometry'], axis=1)\n",
    "X = X.drop(['Li site dopant electroneg.','La site dopant electroneg.','Zr site dopant electroneg.'], axis=1)\n",
    "X = X.drop(['Li site dopant ion charge','La site dopant ion charge','Zr site dopant ion charge'], axis=1)\n",
    "X = X.drop(['Li site dopant crystal rad.','La site dopant crystal rad.','Zr site dopant crystal rad.'], axis=1)\n",
    "# X = X.drop(['Li site dopant electroneg.','La site dopant electroneg.','Zr site dopant electroneg.'], axis=1)\n",
    "X = X.drop(['Li site dopant molar mass','La site dopant molar mass','Zr site dopant molar mass'], axis=1)\n",
    "X = X.drop(['Li site dopant atomic number','La site dopant atomic number','Zr site dopant atomic number'], axis=1)\n",
    "X = X.drop(['Li site dopant e_ionisation','La site dopant e_ionisation','Zr site dopant e_ionisation'], axis=1)\n",
    "X = X.drop(['Li site dopant electron affinity','La site dopant electron affinity','Zr site dopant electron affinity'], axis=1)\n",
    "X = X.drop(['Li site dopant atomic radius','La site dopant atomic radius','Zr site dopant atomic radius'], axis=1)\n",
    "X = X.drop(['li_dopant','la_dopant','zr_dopant'], axis=1)\n",
    "\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014a9f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "import pandas as pd\n",
    "\n",
    "##########################\n",
    "\n",
    "knn_imputer = KNNImputer(n_neighbors=3)\n",
    "# Fit and transform the data to impute the missing values\n",
    "X_knn = knn_imputer.fit_transform(X)\n",
    "\n",
    "# Convert back X_knn back to a DataFrame\n",
    "X_knn = pd.DataFrame(data=X_knn, columns=X.columns)\n",
    "\n",
    "Y = X_knn['log_cond']\n",
    "\n",
    "# Drop 'log_cond' \n",
    "X_knn = X_knn.drop('log_cond', axis=1)\n",
    "\n",
    "\n",
    "##########################\n",
    "\n",
    "# # Sort the DataFrame by the \"log_cond\" column\n",
    "# X_sorted = X.sort_values(by='log_cond')\n",
    "\n",
    "# # # Perform linear interpolation on the \"Relative density\" column\n",
    "# X_filled = X_sorted.interpolate(method='linear', limit_direction='both', inplace=False)\n",
    "# Y=X_filled['log_cond']\n",
    "\n",
    "# X_filled=X_filled.drop('log_cond', axis=1)\n",
    "\n",
    "\n",
    "# X_filled.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29186548",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_knn.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7a76a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import make_regression\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor,HistGradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f262ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of regression models \n",
    "models = [\n",
    "    HistGradientBoostingRegressor(),\n",
    "    LinearRegression(),\n",
    "    Ridge(),\n",
    "    RandomForestRegressor(),\n",
    "    GradientBoostingRegressor(),\n",
    "    KNeighborsRegressor(),\n",
    "    XGBRegressor(),\n",
    "    LGBMRegressor(),\n",
    "    CatBoostRegressor()\n",
    "]\n",
    "\n",
    "# Create a list to store the results\n",
    "results = []\n",
    "\n",
    "# number of iterations\n",
    "num_iterations = 100\n",
    "\n",
    "# Iterating over the models and evaluate each one 100 times\n",
    "for model in models:\n",
    "    avg_mse = 0\n",
    "    avg_r2 = 0\n",
    "    \n",
    "    model_name = type(model).__name__\n",
    "    \n",
    "    for _ in range(num_iterations):\n",
    "        # Splitting data into training and testing sets for each iteration\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(X_knn, Y, test_size=0.25, random_state=42, shuffle=True)\n",
    "        \n",
    "        # Model fitting\n",
    "        model.fit(X_train, Y_train)\n",
    "        Y_train_pred = model.predict(X_train)\n",
    "        Y_test_pred = model.predict(X_test)\n",
    "        \n",
    "        # Mean squared error & R2-score\n",
    "        mse = mean_squared_error(Y_test, Y_test_pred)\n",
    "        r2 = r2_score(Y_test, Y_test_pred)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Average metrics update\n",
    "        avg_mse += mse\n",
    "        avg_r2 += r2\n",
    "    \n",
    "    # Calculating the average metrics over the iterations\n",
    "    avg_mse /= num_iterations\n",
    "    avg_r2 /= num_iterations\n",
    "    results.append({\"Model\": model_name, \"R-squared (R2)\": avg_r2, \"Mean Squared Error (MSE)\": avg_mse})\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167e7817",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.sort_values(by='R-squared (R2)', ascending=False, inplace=True)\n",
    "# Reset the indexes to start from 1\n",
    "results_df.reset_index(drop=True, inplace=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861878eb",
   "metadata": {},
   "source": [
    "## CatBoostRegressor Model ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311ad22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_knn, Y, test_size=0.25, random_state=42, shuffle=True)\n",
    "\n",
    "\n",
    "# model1=CatBoostRegressor(bagging_temperature = 0.5, depth = 3, iterations = 214, l2_leaf_reg = 7,\n",
    "#                         learning_rate = 0.3, random_strength = 0.5)\n",
    "model1=CatBoostRegressor()\n",
    "\n",
    "model1.fit(X_train, Y_train)\n",
    "Y_train_pred = model1.predict(X_train)\n",
    "Y_test_pred = model1.predict(X_test)\n",
    "\n",
    "\n",
    "mse = mean_squared_error(Y_test, Y_test_pred)\n",
    "r2_cat = r2_score(Y_test, Y_test_pred)\n",
    "print('R2 score for the CatBoost Model is: ', r2_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fcf97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Exact vs Predictions\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "# Plot for the training set (red)\n",
    "plt.scatter(Y_train, Y_train_pred, color='blue', alpha=0.5, label='Train Predictions (CatBoost)')\n",
    "\n",
    "# Plot for the test set (blue)\n",
    "plt.scatter(Y_test, Y_test_pred, color='red', alpha=0.5, label='Test Predictions (CatBoost)')\n",
    "\n",
    "plt.plot( [-8,-2.5], [-8,-2.5], 'k--', lw=2)\n",
    "plt.title('Actual vs. Predicted Values for CatBoost')\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d302e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inverse transformation\n",
    "\n",
    "inv_Y_test_pred=np.exp(Y_test_pred*np.log(10))\n",
    "inv_Y_test=np.exp(Y_test*np.log(10))\n",
    "\n",
    " \n",
    "inv_r2_test = r2_score(inv_Y_test, inv_Y_test_pred)\n",
    "\n",
    "r2_cat = r2_score(Y_test, Y_test_pred)\n",
    "\n",
    "print('Log transformation ')\n",
    "print('R2 score for the CatBoostRegressor Model is: ', r2_cat)\n",
    "print('\\n')\n",
    "print('Inverse transformation ')\n",
    "print(f'R-squared (R2) Score for the log Test Set: {inv_r2_test:.4f} \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687c1223",
   "metadata": {},
   "outputs": [],
   "source": [
    "error = np.abs(inv_Y_test-inv_Y_test_pred)\n",
    "err_per = np.abs(inv_Y_test-inv_Y_test_pred)/inv_Y_test\n",
    "pd.set_option('display.float_format', '{:.10f}'.format)\n",
    "X_test_original = df.loc[X_test.index, ['MaterialFormula','source']]\n",
    "df2 = pd.DataFrame({\"MaterialFormula\": X_test_original['MaterialFormula'],\"source\": X_test_original['source'],\n",
    "                    \"Y_test_log\":Y_test,\"Y_test_log_pred\":Y_test_pred,\"Y_test\":inv_Y_test,\n",
    "                    \"Y_test_pred\":inv_Y_test_pred,\"error\": error,\"error percentage\": err_per})\n",
    "\n",
    "pd.set_option('display.float_format', None)\n",
    "\n",
    "# Print the DataFrame\n",
    "df_sorted_descending = df2.sort_values(by='error percentage')\n",
    "df_sorted_descending\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6320290e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import RandomizedSearchCV\n",
    "# from scipy.stats import randint\n",
    "\n",
    "# # Define the parameter grid for hyperparameter tuning\n",
    "# param_dist = {\n",
    "#     'iterations': randint(50, 500),\n",
    "#     'learning_rate': [0.001, 0.01, 0.1, 0.2, 0.3],\n",
    "#     'depth': randint(1, 10),\n",
    "#     'l2_leaf_reg': randint(1, 10),\n",
    "#     'random_strength': [0.1, 0.5, 1, 2, 5],\n",
    "#     'bagging_temperature': [0.1, 0.5, 1, 2, 5],\n",
    "# }\n",
    "\n",
    "# # Initialize the CatBoostRegressor model\n",
    "# model = CatBoostRegressor()\n",
    "\n",
    "# # Perform RandomizedSearchCV for hyperparameter tuning\n",
    "# random_search = RandomizedSearchCV(\n",
    "#     model,\n",
    "#     param_distributions=param_dist,\n",
    "#     n_iter=20,  # Adjust the number of iterations as needed\n",
    "#     cv=3,  # Adjust the number of cross-validation folds as needed\n",
    "#     scoring='neg_mean_squared_error',\n",
    "#     verbose=1,\n",
    "#     n_jobs=-1,\n",
    "# )\n",
    "\n",
    "# # Fit the random search model to the data\n",
    "# random_search.fit(X_train, Y_train)\n",
    "\n",
    "# # Get the best parameters from the search\n",
    "# best_params = random_search.best_params_\n",
    "\n",
    "# # Use the best model for prediction\n",
    "# best_model = random_search.best_estimator_\n",
    "# Y_train_pred = best_model.predict(X_train)\n",
    "# Y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "# # Calculate metrics for the best model\n",
    "# mse = mean_squared_error(Y_test, Y_test_pred)\n",
    "# r2_cat = r2_score(Y_test, Y_test_pred)\n",
    "\n",
    "# # Print the results\n",
    "# print('Best hyperparameters:', best_params)\n",
    "# print('R2 score for the best CatBoostRegressor model:', r2_cat)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace150a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 1:\n",
    "# Best hyperparameters: {'bagging_temperature': 5, 'depth': 4, 'iterations': 410, 'l2_leaf_reg': 4, 'learning_rate': 0.2, 'random_strength': 0.5}\n",
    "# R2 score for the best CatBoostRegressor model: 0.8271191424333637\n",
    "\n",
    "# Test 2:\n",
    "# Best hyperparameters: {'bagging_temperature': 2, 'depth': 4, 'iterations': 405, 'l2_leaf_reg': 4, 'learning_rate': 0.2, 'random_strength': 2}\n",
    "# R2 score for the best CatBoostRegressor model: 0.8297602354808238\n",
    "\n",
    "# Test 3:\n",
    "# Best hyperparameters: {'bagging_temperature': 2, 'depth': 5, 'iterations': 283, 'l2_leaf_reg': 5, 'learning_rate': 0.2, 'random_strength': 0.5}\n",
    "# R2 score for the best CatBoostRegressor model: 0.8327860400451366\n",
    "\n",
    "# Test 4:\n",
    "# Best hyperparameters: {'bagging_temperature': 0.1, 'depth': 2, 'iterations': 395, 'l2_leaf_reg': 5, 'learning_rate': 0.3, 'random_strength': 5}\n",
    "# R2 score for the best CatBoostRegressor model: 0.8121874045282357\n",
    "\n",
    "# Test 5:\n",
    "# Best hyperparameters: {'bagging_temperature': 0.5, 'depth': 3, 'iterations': 214, 'l2_leaf_reg': 7, 'learning_rate': 0.3, 'random_strength': 0.5}\n",
    "# R2 score for the best CatBoostRegressor model: 0.8469166559289\n",
    "\n",
    "# Test 6:\n",
    "# Best hyperparameters: {'bagging_temperature': 2, 'depth': 4, 'iterations': 147, 'l2_leaf_reg': 3, 'learning_rate': 0.3, 'random_strength': 1}\n",
    "# R2 score for the best CatBoostRegressor model: 0.8133142715797372\n",
    "# R2 Score for ionic conductivity: 0.58"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6920d82a",
   "metadata": {},
   "source": [
    "## XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92717c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBRegressor\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_knn, Y, test_size=0.25, random_state=42, shuffle=True)\n",
    "\n",
    "model2 = XGBRegressor()\n",
    "\n",
    "model2.fit(X_train, Y_train)\n",
    "Y_train_pred = model2.predict(X_train)\n",
    "Y_test_pred = model2.predict(X_test)\n",
    "\n",
    "# Calculate metrics for this iteration\n",
    "mse = mean_squared_error(Y_test, Y_test_pred)\n",
    "r2_cat = r2_score(Y_test, Y_test_pred)\n",
    "print('R2 score for the XGBRegressor Model is: ', r2_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe832796",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "# Plot for the training set (red)\n",
    "plt.scatter(Y_train, Y_train_pred, color='blue', alpha=0.5, label='Train Predictions (XGBRegressor)')\n",
    "\n",
    "# Plot for the test set (blue)\n",
    "plt.scatter(Y_test, Y_test_pred, color='red', alpha=0.5, label='Test Predictions (XGBRegressor)')\n",
    "\n",
    "plt.plot( [-8,-2.5], [-8,-2.5], 'k--', lw=2)\n",
    "plt.title('Actual vs. Predicted Values for XGBRegressor')\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
